{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from joblib import parallel_backend\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "vocab = \"ARNDCQEGHILKMFPSTWYVXU\"\n",
    "\n",
    "def one_hot_pad_seqs(s, length, vocab=vocab):\n",
    "    aa_dict = {k: v for v, k in enumerate(vocab)}\n",
    "    embedded = np.zeros([length, len(vocab)])\n",
    "    for i, l in enumerate(s):\n",
    "        if i >= length:\n",
    "            break\n",
    "        idx = aa_dict[l]\n",
    "        embedded[i, idx] = 1\n",
    "    embedded = embedded.flatten()\n",
    "    return embedded\n",
    "\n",
    "def get_seq(df, length=100):\n",
    "    seq = df.sequence.values.tolist()\n",
    "    X = []\n",
    "    for s in seq:\n",
    "        one_hot_encoded = one_hot_pad_seqs(s, length)\n",
    "        gkyi_content = s.count(\"GKYI\") / len(s)\n",
    "        features = np.concatenate([one_hot_encoded, [gkyi_content]])\n",
    "        X.append(features)\n",
    "    return np.array(X)\n",
    "\n",
    "def load_train_data(path, val_split=False):\n",
    "    df = pd.read_csv(path)\n",
    "    df.sequence = df.sequence.apply(\n",
    "        lambda s: re.sub(r\"[^A-Z]\", \"\", s.upper())\n",
    "    )  # remove special characters\n",
    "\n",
    "    if val_split:\n",
    "        train, val = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        return train, val\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def load_test_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.sequence = df.sequence.apply(\n",
    "        lambda s: re.sub(r\"[^A-Z]\", \"\", s.upper())\n",
    "    )  # remove special characters\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    train = load_train_data(\"/Users/hinagaur/Documents/MS_BINF/ML/kaggle/train.csv\", val_split=False)\n",
    "    test = load_test_data(\"/Users/hinagaur/Documents/MS_BINF/ML/kaggle/test.csv\")\n",
    "\n",
    "    print(len(train), len(test))\n",
    "\n",
    "    train_X, test_X = get_seq(train), get_seq(test)\n",
    "\n",
    "    train_y = np.array(train.target.values.tolist())\n",
    "    test_id = test.id.values.tolist()\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 6, 9,12],\n",
    "        'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "        'n_estimators': [20, 30, 40,60]\n",
    "    }\n",
    "\n",
    "    # Initialize XGBoost regressor\n",
    "    xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse')\n",
    "\n",
    "    # Initialize Randomized Search with threading\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        random_search = RandomizedSearchCV(estimator=xgb_reg, param_distributions=param_grid, n_iter=10, cv=3)\n",
    "\n",
    "        # Train XGBoost model with Randomized Search\n",
    "        random_search.fit(train_X, train_y)\n",
    "\n",
    "    # Best parameters\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "    # Cross-validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(random_search.best_estimator_, train_X, train_y, cv=kfold)\n",
    "    print(\"Cross-validation Scores:\", scores)\n",
    "    print(\"Mean RMSE:\", np.mean(scores))\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r_squared = r2_score(train_y, random_search.best_estimator_.predict(train_X))\n",
    "    print(\"R-squared:\", r_squared)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(train_y, random_search.best_estimator_.predict(train_X))\n",
    "    print(\"MAE:\", mae)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(train_y, random_search.best_estimator_.predict(train_X))\n",
    "    print(\"MSE:\", mse)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "    # Make predictions on test set using the best model from Randomized Search\n",
    "    test_y = random_search.predict(test_X)\n",
    "\n",
    "    # Write predictions to file\n",
    "    with open(\"prediction.csv\", \"w\") as f:\n",
    "        f.write(\"id,target\\n\")\n",
    "        for id, y in zip(test_id, test_y):\n",
    "            f.write(f\"{id},{y}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
